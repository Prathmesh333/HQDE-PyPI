{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HQDE System Test Notebook\n",
    "\n",
    "This notebook tests the fixed HQDE (Hierarchical Quantum-Distributed Ensemble Learning) system to verify it works dynamically instead of showing static output.\n",
    "\n",
    "## What this tests:\n",
    "1. Dynamic training vs static simulation\n",
    "2. Real model predictions instead of random outputs\n",
    "3. Adaptive quantization functionality\n",
    "4. Quantum-inspired aggregation\n",
    "5. Synthetic data generation\n",
    "\n",
    "## Run all cells in order to test the system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣ Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add the project directory to Python path\n",
    "# Update this path if your notebook is in a different location\n",
    "project_dir = './'  # Change if needed\n",
    "sys.path.insert(0, project_dir)\n",
    "\n",
    "print(\"Setting up HQDE Test Environment...\")\n",
    "print(f\"Project directory: {os.path.abspath(project_dir)}\")\n",
    "\n",
    "# Test basic imports\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import numpy as np\n",
    "    print(\"SUCCESS: PyTorch and NumPy imported successfully\")\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "except ImportError as e:\n",
    "    print(f\"ERROR: Import failed: {e}\")\n",
    "    print(\"Please install: pip install torch numpy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2️⃣ Test HQDE Core Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test HQDE core components\n",
    "try:\n",
    "    # Add core directory to path\n",
    "    sys.path.insert(0, os.path.join(project_dir, 'hqde', 'core'))\n",
    "    from hqde_system import AdaptiveQuantizer, QuantumInspiredAggregator\n",
    "    print(\"SUCCESS: HQDE Core components imported successfully\")\n",
    "    \n",
    "    # Test AdaptiveQuantizer\n",
    "    print(\"\\nTesting AdaptiveQuantizer...\")\n",
    "    quantizer = AdaptiveQuantizer(base_bits=8, min_bits=4, max_bits=16)\n",
    "    dummy_weights = torch.randn(100, 50)\n",
    "    importance_scores = quantizer.compute_importance_score(dummy_weights)\n",
    "    print(f\"   Importance scores shape: {importance_scores.shape}\")\n",
    "    \n",
    "    quantized_weights, metadata = quantizer.adaptive_quantize(dummy_weights, importance_scores)\n",
    "    print(f\"   Compression ratio: {metadata['compression_ratio']:.2f}x\")\n",
    "    print(f\"   Average bits: {metadata['avg_bits']}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"ERROR: HQDE Core import failed: {e}\")\n",
    "    print(\"Make sure the HQDE project files are in the correct directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3️⃣ Test Quantum-Inspired Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Testing QuantumInspiredAggregator...\")\n",
    "    \n",
    "    aggregator = QuantumInspiredAggregator(noise_scale=0.01, exploration_factor=0.1)\n",
    "    print(\"SUCCESS: QuantumInspiredAggregator created\")\n",
    "    \n",
    "    # Create multiple weight sets (simulating different ensemble members)\n",
    "    weight_list = [torch.randn(50, 30) for _ in range(4)]\n",
    "    efficiency_scores = [0.9, 0.8, 0.85, 0.75]\n",
    "    \n",
    "    # Test aggregation\n",
    "    aggregated = aggregator.efficiency_weighted_aggregation(weight_list, efficiency_scores)\n",
    "    print(f\"SUCCESS: Aggregation completed - shape: {aggregated.shape}\")\n",
    "    \n",
    "    # Test quantum noise injection\n",
    "    noisy_weights = aggregator.quantum_noise_injection(weight_list[0])\n",
    "    noise_magnitude = torch.mean(torch.abs(noisy_weights - weight_list[0]))\n",
    "    print(f\"SUCCESS: Quantum noise injected - magnitude: {noise_magnitude:.6f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Quantum aggregator test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4️⃣ Test Dynamic Training vs Static Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing Dynamic vs Static Training Behavior...\")\n",
    "\n",
    "def run_training_simulation(seed=None):\n",
    "    \"\"\"Run a simple training simulation and return final loss.\"\"\"\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    \n",
    "    # Simple model\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(10, 20),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(20, 1)\n",
    "    )\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    # Train for a few steps\n",
    "    losses = []\n",
    "    for step in range(10):\n",
    "        # Random data\n",
    "        x = torch.randn(16, 10)\n",
    "        y = torch.randn(16, 1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    return losses[-1], losses\n",
    "\n",
    "# Run multiple simulations with different random seeds\n",
    "results = []\n",
    "for run, seed in enumerate([42, 123, 999, None], 1):\n",
    "    final_loss, loss_history = run_training_simulation(seed)\n",
    "    results.append(final_loss)\n",
    "    print(f\"Run {run} (seed={seed}): final loss = {final_loss:.6f}\")\n",
    "\n",
    "# Check if results are different (indicating dynamic behavior)\n",
    "loss_variance = np.var(results)\n",
    "print(f\"\\nVariance across runs: {loss_variance:.8f}\")\n",
    "\n",
    "if loss_variance > 1e-6:\n",
    "    print(\"SUCCESS: DYNAMIC BEHAVIOR CONFIRMED - Results vary between runs\")\n",
    "else:\n",
    "    print(\"WARNING: Results are very similar - might indicate static behavior\")\n",
    "\n",
    "# Visualize loss curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, seed in enumerate([42, 123, 999]):\n",
    "    _, loss_history = run_training_simulation(seed)\n",
    "    plt.plot(loss_history, label=f'Seed {seed}', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Training Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Dynamic Training Behavior - Different Loss Curves')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5️⃣ Test Synthetic CIFAR-10 Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Testing Synthetic CIFAR-10 Data Generation...\")\n",
    "    \n",
    "    # Add examples directory to path\n",
    "    sys.path.insert(0, os.path.join(project_dir, 'examples'))\n",
    "    from cifar10_synthetic_test import SyntheticCIFAR10DataLoader\n",
    "    \n",
    "    # Create synthetic data loader\n",
    "    data_loader = SyntheticCIFAR10DataLoader(\n",
    "        num_samples=200, \n",
    "        batch_size=32,\n",
    "        num_classes=10\n",
    "    )\n",
    "    \n",
    "    print(f\"SUCCESS: Synthetic data loader created\")\n",
    "    print(f\"   Total samples: {data_loader.num_samples}\")\n",
    "    print(f\"   Batch size: {data_loader.batch_size}\")\n",
    "    print(f\"   Number of batches: {len(data_loader)}\")\n",
    "    \n",
    "    # Test data generation\n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        if i >= 3:  # Test first 3 batches\n",
    "            break\n",
    "        \n",
    "        print(f\"\\n   Batch {i+1}:\")\n",
    "        print(f\"     Images shape: {images.shape}\")\n",
    "        print(f\"     Labels shape: {labels.shape}\")\n",
    "        print(f\"     Image range: [{images.min():.3f}, {images.max():.3f}]\")\n",
    "        print(f\"     Unique labels: {torch.unique(labels).tolist()}\")\n",
    "        \n",
    "        # Display class distribution\n",
    "        unique, counts = torch.unique(labels, return_counts=True)\n",
    "        class_dist = dict(zip(unique.tolist(), counts.tolist()))\n",
    "        print(f\"     Class distribution: {class_dist}\")\n",
    "    \n",
    "    print(\"\\nSUCCESS: Synthetic CIFAR-10 data test completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Synthetic data test failed: {e}\")\n",
    "    print(\"Make sure the cifar10_synthetic_test.py file is available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6️⃣ Test Real Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing Real Model Predictions vs Random Outputs...\")\n",
    "\n",
    "# Create a simple classifier\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_size=10, num_classes=5):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 32)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.fc3 = nn.Linear(16, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Create model and data\n",
    "model = SimpleClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Generate test data\n",
    "torch.manual_seed(42)\n",
    "X_test = torch.randn(100, 10)\n",
    "y_test = torch.randint(0, 5, (100,))\n",
    "\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"Test labels shape: {y_test.shape}\")\n",
    "\n",
    "# Test before training (random predictions)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    initial_pred = model(X_test)\n",
    "    _, initial_pred_classes = torch.max(initial_pred, dim=1)\n",
    "    initial_accuracy = (initial_pred_classes == y_test).float().mean()\n",
    "\n",
    "print(f\"\\nBefore Training:\")\n",
    "print(f\"   Prediction accuracy: {initial_accuracy:.4f} ({initial_accuracy*100:.2f}%)\")\n",
    "print(f\"   Prediction range: [{initial_pred.min():.3f}, {initial_pred.max():.3f}]\")\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nTraining model...\")\n",
    "model.train()\n",
    "for epoch in range(20):\n",
    "    # Generate training data\n",
    "    X_train = torch.randn(80, 10)\n",
    "    y_train = torch.randint(0, 5, (80,))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"   Epoch {epoch+1}/20, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Test after training (learned predictions)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    final_pred = model(X_test)\n",
    "    _, final_pred_classes = torch.max(final_pred, dim=1)\n",
    "    final_accuracy = (final_pred_classes == y_test).float().mean()\n",
    "\n",
    "print(f\"\\nAfter Training:\")\n",
    "print(f\"   Prediction accuracy: {final_accuracy:.4f} ({final_accuracy*100:.2f}%)\")\n",
    "print(f\"   Prediction range: [{final_pred.min():.3f}, {final_pred.max():.3f}]\")\n",
    "\n",
    "# Compare results\n",
    "accuracy_improvement = final_accuracy - initial_accuracy\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"   Accuracy improvement: {accuracy_improvement:+.4f}\")\n",
    "\n",
    "if accuracy_improvement > 0.1:\n",
    "    print(\"   SUCCESS: MODEL LEARNED - Real dynamic training confirmed!\")\n",
    "elif accuracy_improvement > 0:\n",
    "    print(\"   SUCCESS: Some improvement detected - Dynamic behavior working\")\n",
    "else:\n",
    "    print(\"   WARNING: No improvement - Could indicate static behavior\")\n",
    "\n",
    "# Visualize prediction distributions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Before training\n",
    "ax1.hist(initial_pred.flatten().numpy(), bins=20, alpha=0.7, color='blue')\n",
    "ax1.set_title('Before Training (Random)')\n",
    "ax1.set_xlabel('Prediction Values')\n",
    "ax1.set_ylabel('Frequency')\n",
    "\n",
    "# After training\n",
    "ax2.hist(final_pred.flatten().numpy(), bins=20, alpha=0.7, color='green')\n",
    "ax2.set_title('After Training (Learned)')\n",
    "ax2.set_xlabel('Prediction Values')\n",
    "ax2.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7️⃣ Summary and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"HQDE SYSTEM TEST SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Count successful tests\n",
    "test_results = {\n",
    "    'Core Components': 'quantizer' in locals() or 'aggregator' in locals(),\n",
    "    'Dynamic Training': 'loss_variance' in locals() and loss_variance > 1e-6,\n",
    "    'Synthetic Data': 'data_loader' in locals(),\n",
    "    'Real Predictions': 'accuracy_improvement' in locals() and accuracy_improvement > 0,\n",
    "}\n",
    "\n",
    "passed_tests = sum(test_results.values())\n",
    "total_tests = len(test_results)\n",
    "\n",
    "for test_name, result in test_results.items():\n",
    "    status = \"PASS\" if result else \"FAIL\"\n",
    "    print(f\"   {test_name}: {status}\")\n",
    "\n",
    "print(f\"\\nOverall Result: {passed_tests}/{total_tests} tests passed\")\n",
    "\n",
    "if passed_tests == total_tests:\n",
    "    print(\"\\nEXCELLENT! All tests passed.\")\n",
    "    print(\"   The HQDE system is working with dynamic behavior!\")\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"   1. Install full dependencies: pip install ray psutil matplotlib\")\n",
    "    print(\"   2. Run comprehensive test: python -m hqde --mode demo\")\n",
    "    print(\"   3. Try full evaluation: python -m hqde --mode test --workers 4\")\n",
    "elif passed_tests >= total_tests // 2:\n",
    "    print(\"\\nGOOD PROGRESS! Most tests passed.\")\n",
    "    print(\"   The system is partially working. Check the failed tests above.\")\n",
    "else:\n",
    "    print(\"\\nNEEDS ATTENTION! Many tests failed.\")\n",
    "    print(\"   Please check your installation and file paths.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"HQDE Dynamic Implementation Test Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}