# Changelog

All notable changes to the HQDE project will be documented in this file.

## [0.1.5] - 2025-02-03

### ðŸš€ Major Accuracy Improvements

#### Fixed Critical Issues
- **âœ… CRITICAL FIX #1: Enabled Weight Aggregation**
  - Workers now aggregate and synchronize weights after each epoch (FedAvg style)
  - Previously, workers trained independently without sharing knowledge
  - This was the #1 cause of poor accuracy - workers never communicated during training
  - Expected improvement: +15-20% accuracy on complex datasets

- **âœ… FIX #3: Reduced Dropout for Ensemble Training**
  - Default dropout reduced from 0.5 to 0.15 for ensemble members
  - Dropout is redundant when using ensembles (ensemble itself provides regularization)
  - Each worker now gets a slightly different dropout rate (0.12-0.18) for diversity
  - Expected improvement: +3-5% accuracy

- **âœ… FIX #5: Added Learning Rate Scheduling**
  - Implemented CosineAnnealingLR scheduler for all workers
  - Learning rate decays from initial value to 1e-6 over training
  - Helps models converge better on complex datasets
  - Expected improvement: +2-4% accuracy

- **âœ… FIX #6: Added Ensemble Diversity**
  - Each worker now has different learning rates: [0.001, 0.0008, 0.0012, 0.0009]
  - Each worker has different dropout rates: [0.15, 0.18, 0.12, 0.16]
  - Diversity prevents all workers from making the same mistakes
  - Expected improvement: +2-3% accuracy

#### Additional Improvements
- **Gradient Clipping**: Added gradient norm clipping (max_norm=1.0) for training stability
- **Better Logging**: Added detailed logging for weight aggregation and learning rate changes
- **Model Kwargs Copying**: Fixed potential mutation issues when creating diverse workers

### Expected Performance Gains

| Dataset | v0.1.4 (5 epochs) | v0.1.5 (40 epochs) | Expected Gain |
|---------|-------------------|-------------------|---------------|
| MNIST | ~98% | ~99.2% | +1.2% |
| Fashion-MNIST | ~87% | ~91-92% | +4-5% |
| CIFAR-10 | ~59% | ~75-80% | +16-21% |
| SVHN | ~72% | ~85-88% | +13-16% |
| CIFAR-100 | ~14% | ~45-55% | +31-41% |

### Technical Details

#### Weight Aggregation (FedAvg)
```python
# After each epoch:
1. Collect weights from all workers
2. Average weights across workers
3. Broadcast averaged weights back to all workers
4. Workers continue training with synchronized weights
```

#### Ensemble Diversity Strategy
```python
Worker 0: LR=0.001, Dropout=0.15
Worker 1: LR=0.0008, Dropout=0.18
Worker 2: LR=0.0012, Dropout=0.12
Worker 3: LR=0.0009, Dropout=0.16
```

#### Learning Rate Schedule
```python
CosineAnnealingLR:
- Initial LR: 0.001 (varies per worker)
- Final LR: 1e-6
- T_max: 50 epochs
- Smooth cosine decay
```

### Migration Guide

#### For Users
Simply upgrade to the latest version:
```bash
pip install hqde --upgrade
```

No code changes required! The improvements are automatic.

#### For Model Definitions
If your model supports `dropout_rate` parameter, HQDE will automatically inject diverse dropout rates:
```python
class MyModel(nn.Module):
    def __init__(self, num_classes=10, dropout_rate=0.15):  # âœ… Add this parameter
        super().__init__()
        self.dropout = nn.Dropout(dropout_rate)  # âœ… Use the parameter
        # ... rest of model
```

If your model doesn't support `dropout_rate`, it will use the default architecture (no changes needed).

### Breaking Changes
None. This release is fully backward compatible.

### Known Issues
- Complex datasets (CIFAR-100) may still require 60+ epochs for optimal performance
- Very small batch sizes (<16) may cause instability with weight aggregation

### Recommendations
1. **Use 40+ epochs** for complex datasets (CIFAR-10, CIFAR-100, STL-10)
2. **Use 20-30 epochs** for medium datasets (SVHN, Fashion-MNIST)
3. **Use 10-15 epochs** for simple datasets (MNIST)
4. **Batch size**: Keep â‰¥32 for stable training
5. **Workers**: 4 workers is optimal for 2 GPUs (0.5 GPU per worker)

---

## [0.1.4] - 2025-01-XX

### Added
- GPU support with fractional GPU allocation
- Improved Ray worker management
- Better error handling and logging

### Fixed
- GPU memory management issues
- Worker initialization bugs

---

## [0.1.3] - 2025-01-XX

### Added
- Initial PyPI release
- Basic HQDE functionality
- Quantum-inspired aggregation
- Adaptive quantization
- Distributed training with Ray

---

## [0.1.0] - 2024-12-XX

### Added
- Initial development version
- Core HQDE architecture
- Proof of concept implementation
