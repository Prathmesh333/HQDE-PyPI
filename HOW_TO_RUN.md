# HQDE Framework - Installation and Usage Guide

**Version:** 0.1.5  
**Last Updated:** February 2025

This guide provides instructions for installing and running the HQDE (Hierarchical Quantum-Distributed Ensemble Learning) framework.

## ðŸŽ‰ What's New in v0.1.5

**Critical Accuracy Improvements:**
- âœ… **Enabled Weight Aggregation (FedAvg)** - Workers now share knowledge after each epoch
- âœ… **Reduced Dropout to 0.15** - Optimized for ensemble learning
- âœ… **Added Learning Rate Scheduling** - CosineAnnealingLR for better convergence
- âœ… **Added Ensemble Diversity** - Different LR and dropout per worker
- âœ… **Added Gradient Clipping** - Improved training stability

**Expected Performance Gains:**
- CIFAR-10: +16-21% accuracy improvement
- SVHN: +13-16% accuracy improvement  
- CIFAR-100: +31-41% accuracy improvement

**Upgrade to v0.1.5:**
```bash
pip install hqde==0.1.5 --upgrade
```

See [CHANGELOG.md](CHANGELOG.md) for complete details.

---

## Prerequisites

### System Requirements
- **Python**: 3.9 or higher
- **GPU**: CUDA-compatible GPU (optional but recommended)
- **Memory**: At least 4GB RAM
- **Storage**: 2GB free space

### Dependencies
The framework automatically installs:
- PyTorch (â‰¥2.8.0)
- Ray (â‰¥2.49.2)
- NumPy (â‰¥2.0.2)
- scikit-learn (â‰¥1.6.1)
- psutil (â‰¥7.1.0)

---

## Installation

### From PyPI (Recommended)
```bash
pip install hqde
```

### From Source
```bash
git clone https://github.com/Prathmesh333/HQDE-PyPI.git
cd HQDE-PyPI
pip install -e .
```

### Using PYTHONPATH (Development)
```powershell
# Windows PowerShell
cd "path\to\HQDE-PyPI"
$env:PYTHONPATH = "."
python examples/cifar10_synthetic_test.py
```

```bash
# Linux/Mac
cd "/path/to/HQDE-PyPI"
export PYTHONPATH=.
python examples/cifar10_synthetic_test.py
```

---

## Quick Start

```python
from hqde import create_hqde_system
import torch.nn as nn

class MyModel(nn.Module):
    def __init__(self, num_classes=10, dropout_rate=0.15):  # ðŸ†• v0.1.5: Add dropout_rate
        super().__init__()
        self.layers = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1),
            nn.ReLU(),
            nn.Dropout(dropout_rate),  # ðŸ†• v0.1.5: Use dropout_rate parameter
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(),
            nn.Dropout(dropout_rate),  # ðŸ†• v0.1.5: Use dropout_rate parameter
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(64, num_classes)
        )

    def forward(self, x):
        return self.layers(x)

# Create HQDE system
hqde_system = create_hqde_system(
    model_class=MyModel,
    model_kwargs={'num_classes': 10},
    num_workers=4,
    quantization_config={'base_bits': 8, 'min_bits': 4, 'max_bits': 16},
    aggregation_config={'noise_scale': 0.005, 'exploration_factor': 0.1}
)

# Train (ðŸ†• v0.1.5: Use 40+ epochs for complex datasets)
metrics = hqde_system.train(train_loader, num_epochs=40)

# Predict
predictions = hqde_system.predict(test_loader)

# Cleanup
hqde_system.cleanup()
```

**Expected Output (v0.1.5):**
```
Epoch 1/40, Average Loss: 2.3045, LR: 0.001000
  â†’ Weights aggregated and synchronized at epoch 1
Epoch 2/40, Average Loss: 1.8234, LR: 0.000998
  â†’ Weights aggregated and synchronized at epoch 2
...
Epoch 40/40, Average Loss: 0.4521, LR: 0.000001
  â†’ Weights aggregated and synchronized at epoch 40

Final Test Accuracy: 78.5% (CIFAR-10)
```

---

## Examples

| Example | Description | Command |
|---------|-------------|---------|
| Quick Start | Basic demonstration | `python examples/quick_start.py` |
| Synthetic CIFAR-10 | Comprehensive benchmark | `python examples/cifar10_synthetic_test.py` |
| Real CIFAR-10 | Full dataset test | `python examples/cifar10_test.py` |

---

## Configuration

### Quantization
```python
quantization_config = {
    'base_bits': 8,    # Default precision
    'min_bits': 4,     # High compression
    'max_bits': 16     # High precision
}
```

### Quantum Aggregation
```python
aggregation_config = {
    'noise_scale': 0.005,
    'exploration_factor': 0.1,
    'entanglement_strength': 0.1
}
```

### Distributed Workers
```python
num_workers = 4  # Adjust based on available CPU cores/GPUs
```

---

## Performance Benchmarks

### v0.1.5 Accuracy Improvements

| Dataset | v0.1.4 (5 epochs) | v0.1.5 (40 epochs) | Improvement |
|---------|-------------------|-------------------|-------------|
| MNIST | ~98% | ~99.2% | +1.2% |
| Fashion-MNIST | ~87% | ~91-92% | +4-5% |
| CIFAR-10 | ~59% | ~75-80% | **+16-21%** |
| SVHN | ~72% | ~85-88% | **+13-16%** |
| CIFAR-100 | ~14% | ~45-55% | **+31-41%** |

### Resource Efficiency

| Metric | Traditional Ensemble | HQDE | Improvement |
|--------|---------------------|------|-------------|
| Memory Usage | 2.4 GB | 0.6 GB | 4x reduction |
| Training Time | 45 min | 12 min | 3.75x faster |
| Communication | 800 MB | 100 MB | 8x less data |

---

## Recommendations for v0.1.5

1. **Epochs** (ðŸ†• IMPORTANT):
   - **Complex datasets** (CIFAR-10, CIFAR-100, STL-10): Use 40+ epochs
   - **Medium datasets** (SVHN, Fashion-MNIST): Use 20-30 epochs
   - **Simple datasets** (MNIST): Use 10-15 epochs
   - More epochs needed in v0.1.5 due to FedAvg weight synchronization

2. **Batch size**: Keep â‰¥32 for stable training with weight aggregation

3. **Workers**: 4 workers is optimal for 2 GPUs (0.5 GPU per worker)

4. **Model Definition** (Optional): Add `dropout_rate` parameter for ensemble diversity:
   ```python
   def __init__(self, num_classes=10, dropout_rate=0.15):
       # HQDE will inject different dropout rates per worker
   ```

5. **Monitoring**: Look for these indicators of successful v0.1.5 training:
   - "Weights aggregated and synchronized at epoch X" messages
   - Learning rate (LR) displayed and gradually decreasing
   - Loss decreasing smoothly across epochs

---

## Troubleshooting

### Module Not Found
```bash
pip install hqde==0.1.5
# or
export PYTHONPATH=.  # from project root
```

### Ray Issues
```python
import ray
ray.shutdown()
ray.init(ignore_reinit_error=True)
```

### CUDA Out of Memory
- Reduce `batch_size` to 32
- Reduce `num_workers` to 2
- Use CPU: set `device = "cpu"`

### v0.1.5 Specific Issues ðŸ†•

#### Not Seeing Weight Aggregation Messages
**Problem**: Training runs but no "Weights aggregated and synchronized" messages

**Solution**: 
1. Verify version: `import hqde; print(hqde.__version__)` should show `0.1.5`
2. Reinstall: `pip install hqde==0.1.5 --upgrade --force-reinstall`

#### Accuracy Not Improving
**Problem**: Still getting low accuracy even with v0.1.5

**Checklist**:
- [ ] Using v0.1.5 (check version)
- [ ] Using 40+ epochs for complex datasets
- [ ] Seeing "Weights aggregated" messages
- [ ] Seeing learning rate (LR) displayed
- [ ] Batch size â‰¥32
- [ ] No errors during training

#### Training Slower Than Expected
**Problem**: v0.1.5 training is slower than v0.1.4

**Explanation**: This is expected! Weight aggregation adds overhead, but the accuracy gains (+15-25%) are worth it. Each epoch is slightly slower, but you get much better results.

---

## Documentation

For detailed technical documentation, see:
- [README.md](README.md) - Overview and API reference
- [docs/TECHNICAL_DOCUMENTATION.md](docs/TECHNICAL_DOCUMENTATION.md) - Complete technical guide
- [docs/QUANTUM_ALGORITHMS_DEEP_DIVE.md](docs/QUANTUM_ALGORITHMS_DEEP_DIVE.md) - Quantum-inspired algorithms
- [docs/DISTRIBUTED_COMPUTING_DEEP_DIVE.md](docs/DISTRIBUTED_COMPUTING_DEEP_DIVE.md) - Distributed architecture
- [docs/META_LEARNING_AND_QA.md](docs/META_LEARNING_AND_QA.md) - Meta-learning and FAQ

---

## Support

- **Issues**: [GitHub Issues](https://github.com/Prathmesh333/HQDE-PyPI/issues)
- **Repository**: https://github.com/Prathmesh333/HQDE-PyPI